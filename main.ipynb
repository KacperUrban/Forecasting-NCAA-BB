{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wregularseason = pd.read_csv(\"data/WRegularSeasonCompactResults.csv\")\n",
    "wtourneyseason = pd.read_csv(\"data/WNCAATourneyCompactResults.csv\")\n",
    "\n",
    "mregularseason = pd.read_csv(\"data/MRegularSeasonCompactResults.csv\")\n",
    "mtourneyseason = pd.read_csv(\"data/MNCAATourneyCompactResults.csv\")\n",
    "\n",
    "wregularseason[\"isTourney\"] = np.zeros(wregularseason.shape[0], dtype=int)\n",
    "wtourneyseason[\"isTourney\"] = np.ones(wtourneyseason.shape[0], dtype=int)\n",
    "\n",
    "mregularseason[\"isTourney\"] = np.zeros(mregularseason.shape[0], dtype=int)\n",
    "mtourneyseason[\"isTourney\"] = np.ones(mtourneyseason.shape[0], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxillar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_loc(row):\n",
    "    if row[\"WLoc\"] == 'A':\n",
    "        return 'H'\n",
    "    elif row[\"WLoc\"] == 'H':\n",
    "        return 'A'\n",
    "    else:\n",
    "        return 'N'\n",
    "\n",
    "def transform_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.drop([\"DayNum\", \"WScore\", \"LScore\", \"NumOT\", \"WLoc\"], axis=1)\n",
    "    df[\"Result\"] = 1\n",
    "    inv_df = df.copy()\n",
    "    inv_df[[\"WTeamID\", \"LTeamID\"]] = inv_df[[\"LTeamID\", \"WTeamID\"]]\n",
    "    inv_df[\"Result\"] = 0\n",
    "    \n",
    "    merged_df = pd.concat([df, inv_df], axis=0).reset_index(drop=True)\n",
    "    return merged_df\n",
    "\n",
    "def make_preds_for_submission(clf, filepath_sub, gender):\n",
    "    df = pd.read_csv(filepath_sub)\n",
    "    df[['Season', 'WTeamID', 'LTeamID']] = df['ID'].str.split('_', expand=True).astype(int)\n",
    "    df['isTourney'] = 1\n",
    "    if gender == \"W\":\n",
    "        df = df.loc[df.WTeamID < 3000]\n",
    "    else:\n",
    "        df = df.loc[df.WTeamID > 3000]\n",
    "    X_features = df.iloc[:, 2:]\n",
    "    pred_probs = np.max(clf.predict_proba(X_features), axis=1)\n",
    "    df[\"Pred\"] = np.round(pred_probs, 4)\n",
    "    return df[[\"ID\", \"Pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wprep = pd.concat([transform_data(wregularseason), transform_data(wtourneyseason)], axis=0).reset_index(drop=True)\n",
    "mprep = pd.concat([transform_data(mregularseason), transform_data(mtourneyseason)], axis=0).reset_index(drop=True)\n",
    "\n",
    "X_men = mprep.drop(\"Result\", axis=1)\n",
    "y_men = mprep.Result\n",
    "\n",
    "X_women = wprep.drop(\"Result\", axis=1)\n",
    "y_women = wprep.Result\n",
    "\n",
    "X_trainm, X_testm, y_trainm, y_testm = train_test_split(X_men, y_men, test_size=0.1, random_state=42)\n",
    "X_trainw, X_testw, y_trainw, y_testw = train_test_split(X_women, y_women, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score for mens data: 0.25\n",
      "Brier score for womens data: 0.25\n"
     ]
    }
   ],
   "source": [
    "log_regm = LogisticRegression()\n",
    "log_regw = LogisticRegression()\n",
    "\n",
    "log_regm.fit(X_trainm, y_trainm)\n",
    "log_regw.fit(X_trainw, y_trainw)\n",
    "\n",
    "pred_probsm = log_regm.predict_proba(X_testm)[:, 1]\n",
    "pred_probsw = log_regw.predict_proba(X_testw)[:, 1]\n",
    "\n",
    "print(f\"Brier score for mens data: {np.round(brier_score_loss(y_testm, pred_probsm), 3).item()}\")\n",
    "print(f\"Brier score for womens data: {np.round(brier_score_loss(y_testw, pred_probsw), 3).item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamlistm = sorted(mprep.WTeamID.unique())\n",
    "teamlistw = sorted(wprep.WTeamID.unique())\n",
    "\n",
    "mens_results = make_preds_for_submission(log_regm, \"data/SampleSubmissionStage2.csv\", \"W\")\n",
    "womens_results = make_preds_for_submission(log_regw, \"data/SampleSubmissionStage2.csv\", \"M\")\n",
    "\n",
    "final_result = pd.concat([mens_results, womens_results], axis=0).reset_index(drop=True)\n",
    "final_result.to_csv(\"submission_result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
